"""
æ•°æ®é›†æµ‹è¯•è„šæœ¬

ç”¨äºéªŒè¯æ•°æ®é›†åŠ è½½å’Œé¢„å¤„ç†æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import torch
from utils.datasets import create_dataloader


def test_dataloader(dataset_type, root_dir, is_train=True):
    """
    æµ‹è¯•æ•°æ®åŠ è½½å™¨

    Args:
        dataset_type: æ•°æ®é›†ç±»å‹ ('Rain100L' æˆ– 'Rain100H')
        root_dir: æ•°æ®é›†æ ¹ç›®å½•
        is_train: æ˜¯å¦ä¸ºè®­ç»ƒæ¨¡å¼
    """
    print(f"\n{'='*60}")
    print(f"æµ‹è¯• {dataset_type} æ•°æ®é›† ({'è®­ç»ƒ' if is_train else 'éªŒè¯'}æ¨¡å¼)")
    print(f"{'='*60}")
    print(f"æ•°æ®è·¯å¾„: {root_dir}")

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(root_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {root_dir}")
        return False

    try:
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        dataloader = create_dataloader(
            dataset_type=dataset_type,
            root_dir=root_dir,
            batch_size=2,  # æµ‹è¯•æ—¶ä½¿ç”¨å°æ‰¹æ¬¡
            patch_size=256,
            is_train=is_train,
            num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨å•è¿›ç¨‹
            max_samples=10  # æµ‹è¯•æ—¶åªåŠ è½½å°‘é‡æ ·æœ¬
        )

        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"   æ•°æ®é›†å¤§å°: {len(dataloader.dataset)} å¼ å›¾ç‰‡")

        # åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡
        print(f"\nåŠ è½½ç¬¬ä¸€ä¸ªæ‰¹æ¬¡...")
        for batch_idx, batch in enumerate(dataloader):
            rainy, gt, task_label, dummy_kernel = batch

            print(f"âœ… æ‰¹æ¬¡ {batch_idx + 1} åŠ è½½æˆåŠŸ:")
            print(f"   - Rainy shape: {rainy.shape}")
            print(f"   - GT shape: {gt.shape}")
            print(f"   - Task label: {task_label}")
            print(f"   - Dummy kernel shape: {dummy_kernel.shape}")
            print(f"   - Rainy value range: [{rainy.min():.3f}, {rainy.max():.3f}]")
            print(f"   - GT value range: [{gt.min():.3f}, {gt.max():.3f}]")

            # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
            break

        print(f"\nâœ… {dataset_type} æ•°æ®é›†æµ‹è¯•é€šè¿‡!")
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("DFA-DUN æ•°æ®é›†æµ‹è¯•å·¥å…·")
    print("="*60)

    # é»˜è®¤æµ‹è¯•è·¯å¾„ (å¯æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹)
    test_paths = {
        'Rain100L_train': './datasets/Rain100L/train',
        'Rain100L_test': './datasets/Rain100L/test',
        'Rain100H_train': './datasets/Rain100H/train',
        'Rain100H_test': './datasets/Rain100H/test',
    }

    # å¦‚æœå‘½ä»¤è¡Œæä¾›äº†è·¯å¾„ï¼Œä½¿ç”¨å‘½ä»¤è¡Œè·¯å¾„
    if len(sys.argv) > 1:
        custom_path = sys.argv[1]
        print(f"\nä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„: {custom_path}")

        # è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†ç±»å‹
        if 'Rain100L' in custom_path or 'rain100l' in custom_path.lower():
            if 'train' in custom_path.lower():
                test_dataloader('Rain100L', custom_path, is_train=True)
            else:
                test_dataloader('Rain100L', custom_path, is_train=False)
        elif 'Rain100H' in custom_path or 'rain100h' in custom_path.lower():
            if 'train' in custom_path.lower():
                test_dataloader('Rain100H', custom_path, is_train=True)
            else:
                test_dataloader('Rain100H', custom_path, is_train=False)
        else:
            print(f"âš ï¸  æ— æ³•ä»è·¯å¾„æ¨æ–­æ•°æ®é›†ç±»å‹ï¼Œå°è¯•ä¸¤ç§ç±»å‹...")

            # å°è¯• Rain100L
            if not test_dataloader('Rain100L', custom_path, is_train=True):
                # å¦‚æœå¤±è´¥ï¼Œå°è¯• Rain100H
                test_dataloader('Rain100H', custom_path, is_train=True)
    else:
        # ä½¿ç”¨é»˜è®¤è·¯å¾„è¿›è¡Œæµ‹è¯•
        print(f"\nä½¿ç”¨é»˜è®¤æµ‹è¯•è·¯å¾„:")
        for name, path in test_paths.items():
            print(f"  - {name}: {path}")

        print(f"\næç¤º: å¯ä»¥é€šè¿‡å‘½ä»¤è¡ŒæŒ‡å®šè‡ªå®šä¹‰è·¯å¾„")
        print(f"ä¾‹å¦‚: python test_dataset.py /path/to/dataset")

        # æµ‹è¯•æ‰€æœ‰é»˜è®¤è·¯å¾„
        results = []
        for name, path in test_paths.items():
            if 'train' in name:
                dataset_type = 'Rain100L' if 'Rain100L' in name else 'Rain100H'
                result = test_dataloader(dataset_type, path, is_train=True)
                results.append((name, result))
            else:
                dataset_type = 'Rain100L' if 'Rain100L' in name else 'Rain100H'
                result = test_dataloader(dataset_type, path, is_train=False)
                results.append((name, result))

        # æ‰“å°æ€»ç»“
        print(f"\n{'='*60}")
        print("æµ‹è¯•æ€»ç»“:")
        print(f"{'='*60}")

        for name, result in results:
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"  {name}: {status}")

        passed = sum(1 for _, r in results if r)
        total = len(results)
        print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")

        if passed == total:
            print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        else:
            print(f"\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„å’Œæ ¼å¼")


if __name__ == "__main__":
    main()
